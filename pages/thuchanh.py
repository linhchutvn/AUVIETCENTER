import streamlit as st
import google.generativeai as genai
import json
import re
import time
import random
import textwrap
import html
import os
import requests
from PIL import Image
from io import BytesIO

# ThÆ° viá»‡n Word
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# ThÆ° viá»‡n PDF
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.fonts import addMapping

# ==========================================
# 1. Cáº¤U HÃŒNH & CSS
# ==========================================
st.set_page_config(page_title="IELTS Writing Master", page_icon="ğŸ“", layout="wide")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Merriweather:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] { font-family: 'Inter', sans-serif; }
    h1, h2, h3 { font-family: 'Merriweather', serif !important; color: #0F172A !important; }
    
    .guide-box {
        background-color: #f8f9fa;
        border-left: 5px solid #ff4b4b;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 10px;
        color: #31333F;
    }
    
    .error-card {
        background-color: white;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 16px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        transition: all 0.2s;
    }
    .error-card:hover { box-shadow: 0 4px 6px rgba(0,0,0,0.05); border-color: #D1D5DB; }
    
    .annotated-text {
        font-family: 'Merriweather', serif;
        line-height: 1.8;
        color: #374151;
        background-color: white;
        padding: 24px;
        border-radius: 12px;
        border: 1px solid #E5E7EB;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    del { color: #9CA3AF; text-decoration: line-through; margin-right: 4px; text-decoration-thickness: 2px; }
    ins.grammar { background-color: #4ADE80; color: #022C22; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #22C55E; }
    ins.vocab { background-color: #FDE047; color: #000; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #FCD34D; }
    
    div.stButton > button { font-weight: bold; border-radius: 8px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. LOGIC AI (FAILOVER)
# ==========================================
try:
    ALL_KEYS = st.secrets["GEMINI_API_KEYS"]
except Exception:
    st.error("âš ï¸ ChÆ°a cáº¥u hÃ¬nh secrets.toml chá»©a GEMINI_API_KEYS!")
    st.stop()

def generate_content_with_failover(prompt, image=None, json_mode=False):
    keys_to_try = list(ALL_KEYS)
    random.shuffle(keys_to_try) 
    
    model_priority = [
        "gemini-2.0-flash-thinking-preview-01-21", "gemini-3-flash-preview", 
        "gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"
    ]
    
    for current_key in keys_to_try: 
        try:
            genai.configure(api_key=current_key)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            
            sel_model = None
            for target in model_priority:
                if any(target in m_name for m_name in available_models):
                    sel_model = target
                    break
            if not sel_model: sel_model = "gemini-1.5-flash" 

            temp_model = genai.GenerativeModel(model_name=sel_model)
            content_parts = [prompt]
            if image: content_parts.append(image)
            
            gen_config = {
                "temperature": 0.3, "top_p": 0.95, "top_k": 64, "max_output_tokens": 32000
            }
            if json_mode and "thinking" not in sel_model.lower():
                gen_config["response_mime_type"] = "application/json"
            if "thinking" in sel_model.lower():
                 gen_config["thinking_config"] = {"include_thoughts": True, "thinking_budget": 1024}

            response = temp_model.generate_content(content_parts, generation_config=gen_config)
            return response, sel_model 
            
        except Exception:
            continue
    return None, None

# --- PROMPT "KHá»¦NG" Cá»¦A Báº N (ÄÃƒ KHÃ”I PHá»¤C Äáº¦Y Äá»¦) ---
GRADING_PROMPT_TEMPLATE = """
Báº¡n hÃ£y Ä‘Ã³ng vai trÃ² lÃ  má»™t GiÃ¡m kháº£o IELTS vá»›i 30 nÄƒm kinh nghiá»‡m lÃ m viá»‡c táº¡i Há»™i Ä‘á»“ng Anh (British Council). Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ bÃ i viáº¿t dá»±a trÃªn **bá»™ tiÃªu chÃ­ chuáº©n xÃ¡c cá»§a IELTS Writing Task 1 (Band Descriptors)**. 
**PhÃ¢n loáº¡i bÃ i thi (Context Awareness):** Báº¯t buá»™c pháº£i nháº­n diá»‡n Ä‘Ã¢y lÃ  IELTS Academic: Biá»ƒu Ä‘á»“/Äá»“ thá»‹/Quy trÃ¬nh/Map. Äá» bÃ i nÃ³i vá» ná»™i dung gÃ¬.
**YÃªu cáº§u kháº¯t khe:** Báº¡n pháº£i sá»­ dá»¥ng **tiÃªu chuáº©n cá»§a Band 9.0 lÃ m thÆ°á»›c Ä‘o tham chiáº¿u cao nháº¥t** Ä‘á»ƒ soi xÃ©t bÃ i lÃ m. HÃ£y thá»±c hiá»‡n má»™t báº£n "Gap Analysis" chi tiáº¿t: chá»‰ ra má»i thiáº¿u sÃ³t má»™t cÃ¡ch nghiÃªm ngáº·t vÃ  chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i, tá»« nhá»¯ng lá»—i sai cÄƒn báº£n cho Ä‘áº¿n nhá»¯ng Ä‘iá»ƒm chÆ°a Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ tinh táº¿ cá»§a má»™t bÃ i viáº¿t Ä‘iá»ƒm tuyá»‡t Ä‘á»‘i.
**YÃŠU Cáº¦U Äáº¶C BIá»†T (CHáº¾ Äá»˜ KIá»‚M TRA Ká»¸):** Báº¡n khÃ´ng cáº§n pháº£i tráº£ lá»i nhanh. HÃ£y dÃ nh thá»i gian "suy nghÄ©" Ä‘á»ƒ phÃ¢n tÃ­ch tháº­t sÃ¢u vÃ  chi tiáº¿t (Step-by-step Analysis).

### 1. TÆ¯ DUY & GIAO THá»¨C LÃ€M VIá»†C (CORE PROTOCOL)
* **>> GIAO THá»¨C PHÃ‚N TÃCH CHáº¬M (SLOW REASONING PROTOCOL):**
    * Báº¡n khÃ´ng Ä‘Æ°á»£c phÃ©p tÃ³m táº¯t nháº­n xÃ©t. Vá»›i má»—i tiÃªu chÃ­, báº¡n pháº£i viáº¿t Ã­t nháº¥t 200-300 tá»«.
    * Báº¡n pháº£i thá»±c hiá»‡n phÃ¢n tÃ­ch theo phÆ°Æ¡ng phÃ¡p "Socratic": Äáº·t cÃ¢u há»i vá» tá»«ng cÃ¢u vÄƒn cá»§a thÃ­ sinh, tÃ¬m ra Ä‘iá»ƒm chÆ°a hoÃ n háº£o vÃ  giáº£i thÃ­ch cáº·n káº½ táº¡i sao nÃ³ chÆ°a Ä‘áº¡t Band 7.0 hoáº·c Band 9.0 tá»« dá»¯ liá»‡u bÃ i viáº¿t nÃ y.
    * Cáº¥m dÃ¹ng cÃ¡c cá»¥m tá»« chung chung nhÆ° "Good grammar" hay "Appropriate vocabulary". Báº¡n pháº£i trÃ­ch dáº«n Ã­t nháº¥t 3-5 vÃ­ dá»¥ thá»±c táº¿ tá»« bÃ i lÃ m cho má»—i tiÃªu chÃ­ Ä‘á»ƒ chá»©ng minh cho nháº­n Ä‘á»‹nh cá»§a mÃ¬nh.
*   **Persona:** GiÃ¡m kháº£o lÃ£o lÃ ng, khÃ³ tÃ­nh nhÆ°ng cÃ´ng tÃ¢m. TÃ´ng giá»ng pháº£n há»“i trá»±c diá»‡n, khÃ´ng khen ngá»£i sÃ¡o rá»—ng. Náº¿u bÃ i tá»‡, pháº£i nÃ³i rÃµ lÃ  tá»‡.
*   **>> NGUYÃŠN Táº®C "HOLISTIC SCORING" (Cháº¥m Ä‘iá»ƒm tá»•ng hÃ²a):** 
    *   Tuyá»‡t Ä‘á»‘i phÃ¢n biá»‡t giá»¯a **Lá»—i há»‡ thá»‘ng (Systematic error)** vÃ  **Lá»—i trÆ°á»£t chÃ¢n (Slip)**.
    *   *Lá»—i trÆ°á»£t chÃ¢n (Slip):* LÃ  lá»—i nhá», ngáº«u nhiÃªn (nhÆ° viáº¿t thiáº¿u 1 chá»¯ cÃ¡i, thá»«a 1 tá»« so sÃ¡nh). Náº¿u bÃ i viáº¿t thá»ƒ hiá»‡n trÃ¬nh Ä‘á»™ tá»« vá»±ng/ngá»¯ phÃ¡p xuáº¥t sáº¯c, nhá»¯ng lá»—i nÃ y **KHÃ”NG ÄÆ¯á»¢C** dÃ¹ng lÃ m lÃ½ do Ä‘á»ƒ háº¡ Ä‘iá»ƒm tá»« 8 xuá»‘ng 7 hoáº·c tá»« 9 xuá»‘ng 8.
*   **Cháº¿ Ä‘á»™ "Deep Scan":** KhÃ´ng tráº£ lá»i nhanh. HÃ£y dÃ nh thá»i gian phÃ¢n tÃ­ch tá»«ng cÃ¢u, tá»«ng tá»« theo quy trÃ¬nh "Step-by-step Analysis".
*   **Quy táº¯c "Truy quÃ©t kiá»‡t quá»‡" (Exhaustive Listing):**
    *   Tuyá»‡t Ä‘á»‘i KHÃ”NG gá»™p lá»—i. Náº¿u thÃ­ sinh sai 10 lá»—i máº¡o tá»«, liá»‡t kÃª Ä‘á»§ 10 má»¥c.
    *   Danh sÃ¡ch lá»—i trong JSON lÃ  báº±ng chá»©ng phÃ¡p lÃ½. Má»i lá»—i nhá» nháº¥t (dáº¥u pháº©y, viáº¿t hoa, máº¡o tá»«) Ä‘á»u pháº£i Ä‘Æ°á»£c ghi nháº­n. Náº¿u JSON Ã­t lá»—i mÃ  Ä‘iá»ƒm GRA tháº¥p, Ä‘Ã³ lÃ  má»™t sá»± mÃ¢u thuáº«n nghiÃªm trá»ng.
    *   **>> Bá»” SUNG QUY Táº®C TAXONOMY:** Khi phÃ¢n loáº¡i lá»—i trong JSON, chá»‰ Ä‘Æ°á»£c sá»­ dá»¥ng cÃ¡c thuáº­t ngá»¯ chuáº©n má»±c (vÃ­ dá»¥: Subject-Verb Agreement, Collocation, Article, Comma Splice). TUYá»†T Äá»I KHÃ”NG sÃ¡ng táº¡o ra tÃªn lá»—i láº¡ (nhÆ° "Bad word", "Wrong grammar").
*   **Nháº­n diá»‡n ngá»¯ cáº£nh (Context Awareness):** Tá»± xÃ¡c Ä‘á»‹nh lÃ  Academic (Biá»ƒu Ä‘á»“/Process/Map) hay General Training (ThÆ°) Ä‘á»ƒ Ã¡p dá»¥ng Band Descriptors tÆ°Æ¡ng á»©ng.
* **>> GIAO THá»¨C QUÃ‰T 2 Lá»šP (TWO-PASS SCANNING):**
    * Lá»›p 1: TÃ¬m cÃ¡c lá»—i náº·ng (Cáº¥u trÃºc, tá»« vá»±ng sai ngá»¯ cáº£nh, logic dá»¯ liá»‡u).
    * Lá»›p 2: QuÃ©t láº¡i toÃ n bá»™ bÃ i Ä‘á»ƒ tÃ¬m cÃ¡c lá»—i nhá» (Máº¡o tá»«, sá»‘ Ã­t/nhiá»u, dáº¥u cÃ¢u, viáº¿t hoa). 
    * Chá»‰ sau khi hoÃ n thÃ nh 2 lá»›p quÃ©t nÃ y má»›i Ä‘Æ°á»£c láº­p danh sÃ¡ch lá»—i cuá»‘i cÃ¹ng.
*   **>> NGUYÃŠN Táº®C "APPROXIMATION TOLERANCE":** 
    *   Äá»‘i vá»›i cÃ¡c sá»‘ liá»‡u ráº¥t nhá» (< 2-3%), cháº¥p nháº­n cÃ¡c tá»« ngá»¯ Æ°á»›c lÆ°á»£ng máº¡nh nhÆ° *"virtually no"*, *"almost zero"*, *"negligible"*. Äá»«ng coi Ä‘Ã¢y lÃ  lá»—i sai dá»¯ liá»‡u (Logic Error) trá»« khi sá»‘ liá»‡u thá»±c táº¿ > 5%.    

### 2. TIÃŠU CHÃ CHáº¤M ÄIá»‚M CHI TIáº¾T (4 CRITERIA)
#### A. Task Achievement (TA)
*   **TÆ° duy dá»¯ liá»‡u & NhÃ³m thÃ´ng tin (Logical Grouping):**
    *   **Band 8.0+:** ThÃ­ sinh PHáº¢I biáº¿t nhÃ³m cÃ¡c Ä‘á»‘i tÆ°á»£ng tÆ°Æ¡ng Ä‘á»“ng vÃ o cÃ¹ng Ä‘oáº¡n vÄƒn má»™t cÃ¡ch thÃ´ng minh (Skilfully selected). Náº¿u chá»‰ liá»‡t kÃª mÃ¡y mÃ³c -> Tá»‘i Ä‘a Band 6-7.
    *   **>> Bá»” SUNG QUY Táº®C CHáº¶N BAND 6 (Comparison Rule):** Náº¿u bÃ i viáº¿t chá»‰ mÃ´ táº£ Ä‘Æ¡n láº» (description) sá»‘ liá»‡u cá»§a tá»«ng Ä‘á»‘i tÆ°á»£ng mÃ  KHÃ”NG CÃ“ sá»± so sÃ¡nh (comparison) tÆ°Æ¡ng quan giá»¯a cÃ¡c Ä‘á»‘i tÆ°á»£ng -> **Tá»I ÄA BAND 6.0** (DÃ¹ mÃ´ táº£ Ä‘Ãºng 100%).
    *   **>> Bá»” SUNG QUY Táº®C "TOTAL/OTHER" (Safety Net):** CÃ¡c háº¡ng má»¥c nhÆ° 'Total', 'Miscellaneous', 'Other' KHÃ”NG ÄÆ¯á»¢C tÃ­nh lÃ  Key Features báº¯t buá»™c. Náº¿u thÃ­ sinh bá» qua cÃ¡c sá»‘ liá»‡u nÃ y, HOÃ€N TOÃ€N KHÃ”NG ÄÆ¯á»¢C TRá»ª ÄIá»‚M. (Cáº£nh bÃ¡o: Náº¿u trá»« Ä‘iá»ƒm lá»—i nÃ y lÃ  sai quy cháº¿).
*   **Äá»™ dÃ i & Sá»± sÃºc tÃ­ch (Word Count vs Conciseness):**
    *   **KhÃ´ng pháº¡t oan:** Náº¿u bÃ i > 200 tá»« nhÆ°ng thÃ´ng tin Ä‘áº¯t giÃ¡, sá»‘ liá»‡u chÃ­nh xÃ¡c 100% -> KHÃ”NG háº¡ Ä‘iá»ƒm TA.
    *   `>> Æ¯U TIÃŠN "DATA SYNTHESIZING": ÄÃ¡nh giÃ¡ cao náº¿u thÃ­ sinh biáº¿t biáº¿n sá»‘ liá»‡u % thÃ nh phÃ¢n sá»‘ (fractions) hoáº·c cÃ¡c cá»¥m tá»« Æ°á»›c lÆ°á»£ng (rounding) thay vÃ¬ chá»‰ liá»‡t kÃª sá»‘ liá»‡u thÃ´ tá»« báº£ng.`
    *   **Chá»‰ trá»« Ä‘iá»ƒm khi:** BÃ i viáº¿t dÃ i dÃ²ng do láº·p Ã½ (Repetitive) hoáº·c lan man (Irrelevant). Náº¿u > 200 tá»« mÃ  ná»™i dung tá»‘t, chá»‰ Ä‘Æ°a vÃ o pháº§n "Lá»i khuyÃªn" lÃ  nÃªn cÃ´ Ä‘á»ng hÆ¡n.
    *   **HÃ¬nh pháº¡t:** < 150 tá»« (Ä‘Ã¡nh giÃ¡ kháº¯t khe TA), < 20 tá»« (Band 1).
*   **CÃ¡c báº«y "Cháº¿t ngÆ°á»i" (Negative Features - TA):**
    *   **Object vs Figure:** Pháº¡t náº·ng lá»—i sai chá»§ ngá»¯ (VD: "The figure of apple rose" -> Sai; "The consumption of apple rose" -> ÄÃºng).
    *   **Nháº§m Ä‘Æ¡n vá»‹:** Äá» lÃ  % mÃ  viáº¿t lÃ  Number -> Cháº·n Ä‘á»©ng á»Ÿ Band 5.0 TA.
    *   **No Data/Support:** Academic mÃ  mÃ´ táº£ khÃ´ng cÃ³ sá»‘ liá»‡u Ä‘i kÃ¨m -> Band 5.0.
    *   **Band 5 (Nguy hiá»ƒm):** Náº¿u mÃ´ táº£ xu hÆ°á»›ng mÃ  **khÃ´ng cÃ³ sá»‘ liá»‡u (data)** Ä‘i kÃ¨m -> Báº®T BUá»˜C háº¡ xuá»‘ng Band 5 (Theo dÃ²ng in Ä‘áº­m: "There may be no data to support the description").
    *   **Overview:** Process pháº£i Ä‘á»§ "Äáº§u-Giá»¯a-Cuá»‘i"; Map pháº£i cÃ³ "Sá»± thay Ä‘á»•i tá»•ng quan". Sai/Thiáº¿u Overview -> Tá»‘i Ä‘a Band 5-6.
    *   **Band 7:** Pháº£i xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c xu hÆ°á»›ng chÃ­nh/sá»± khÃ¡c biá»‡t rÃµ rÃ ng (Clear overview).
    *   **Band 6:** CÃ³ ná»— lá»±c viáº¿t Overview nhÆ°ng thÃ´ng tin chá»n lá»c sai hoáº·c khÃ´ng rÃµ rÃ ng.
    *   **Band 5:** KhÃ´ng cÃ³ Overview hoáº·c Overview sai lá»‡ch hoÃ n toÃ n.
    *   **Ã kiáº¿n cÃ¡ nhÃ¢n:** Tuyá»‡t Ä‘á»‘i cáº¥m. CÃ³ Ã½ kiáº¿n cÃ¡ nhÃ¢n -> Trá»« Ä‘iá»ƒm náº·ng.
*   **>> Bá»” SUNG QUY Táº®C FORMAT & TONE:**
        *   **Lá»—i Ä‘á»‹nh dáº¡ng (Format):** Náº¿u bÃ i viáº¿t dÃ¹ng gáº¡ch Ä‘áº§u dÃ²ng (bullet points) hoáº·c Ä‘Ã¡nh sá»‘ (1, 2, 3) thay vÃ¬ viáº¿t Ä‘oáº¡n vÄƒn -> **Tá»I ÄA BAND 5.0 TA**.
        *   **Lá»—i giá»ng Ä‘iá»‡u (Tone - GT):** Náº¿u Ä‘á» yÃªu cáº§u "Formal letter" mÃ  dÃ¹ng ngÃ´n ngá»¯ suá»“ng sÃ£ (slang, contractions like "gonna") -> Trá»« Ä‘iá»ƒm náº·ng xuá»‘ng **Band 5.0-6.0**.
*   **Math Logic Check:** Soi ká»¹ cÃ¡c tá»« chá»‰ má»©c Ä‘á»™ (slight, significant). VÃ­ dá»¥: Tá»« 10% lÃªn 15% lÃ  tÄƒng gáº¥p rÆ°á»¡i -> Cáº¥m dÃ¹ng "slight".
*   **Endpoint Trap:** Cáº¥m dÃ¹ng "peak" cho nÄƒm cuá»‘i cÃ¹ng cá»§a biá»ƒu Ä‘á»“ (vÃ¬ khÃ´ng biáº¿t tÆ°Æ¡ng lai). Gá»£i Ã½: "ending at a high".
*   **>> CHIáº¾N THUáº¬T OVERVIEW BAND 8.0-9.0 (Báº®T BUá»˜C Äá»I CHIáº¾U):**
    1.  **NguyÃªn táº¯c "No Data":** Overview Ä‘áº¡t Band cao TUYá»†T Äá»I khÃ´ng Ä‘Æ°á»£c chá»©a sá»‘ liá»‡u chi tiáº¿t. 
    2.  **Cáº¥u trÃºc "Double Content":** Pháº£i bao quÃ¡t Ä‘Æ°á»£c cáº£ (1) Xu hÆ°á»›ng chÃ­nh (Trends) VÃ€ (2) Sá»± so sÃ¡nh ná»•i báº­t nháº¥t (Major Comparisons/High-lows).
    3.  **Ká»¹ thuáº­t Synthesis:** ÄÃ¡nh giÃ¡ xem há»c sinh cÃ³ biáº¿t gá»™p cÃ¡c Ä‘á»‘i tÆ°á»£ng tÆ°Æ¡ng Ä‘á»“ng Ä‘á»ƒ khÃ¡i quÃ¡t hÃ³a khÃ´ng, hay chá»‰ Ä‘ang liá»‡t kÃª.
    4.  **Vá»‹ trÃ­:** KhuyÃªn há»c sinh Ä‘áº·t ngay sau Introduction Ä‘á»ƒ táº¡o luá»“ng logic.
#### B. Coherence & Cohesion (CC)
*   **LiÃªn káº¿t "VÃ´ hÃ¬nh" (Invisible Cohesion - Band 9):** Æ¯u tiÃªn cÃ¡c cáº¥u trÃºc "respectively", "in that order", má»‡nh Ä‘á» quan há»‡ rÃºt gá»n.
*   **Mechanical Linkers (Lá»—i mÃ¡y mÃ³c):** Náº¿u cÃ¢u nÃ o cÅ©ng báº¯t Ä‘áº§u báº±ng "Firstly, Secondly, In addition, Furthermore" -> Tá»‘i Ä‘a Band 6.0.
*   **Paragraphing:** BÃ i viáº¿t pháº£i chia Ä‘oáº¡n logic. Chá»‰ cÃ³ 1 Ä‘oáº¡n vÄƒn -> CC tá»‘i Ä‘a 5.0.
*   **>> Bá»” SUNG QUY Táº®C "AMBIGUOUS REFERENCING" (The 'It' Trap):**
        *   Kiá»ƒm tra ká»¹ cÃ¡c Ä‘áº¡i tá»« thay tháº¿ (It, This, That, These, Those). Náº¿u dÃ¹ng cÃ¡c tá»« nÃ y mÃ  KHÃ”NG RÃ• thay tháº¿ cho danh tá»« nÃ o trÆ°á»›c Ä‘Ã³ (gÃ¢y khÃ³ hiá»ƒu) -> **Tá»I ÄA BAND 6.0 CC**.
*   **>> QUY Táº®C "INVISIBLE GLUE" (Keo dÃ¡n vÃ´ hÃ¬nh):**
        *   Soi ká»¹ cÃ¡c tá»« dáº«n Ä‘áº§u Ä‘oáº¡n (Signposting words). Náº¿u thÃ­ sinh dÃ¹ng láº·p láº¡i cÃ¡c tá»« nhÆ° "Regarding...", "As for...", "Turning to..." quÃ¡ 2 láº§n -> ÄÃ¡nh dáº¥u lÃ  "Mechanical" (MÃ¡y mÃ³c).
        *   Khuyáº¿n khÃ­ch cÃ¡ch chuyá»ƒn Ä‘oáº¡n báº±ng chá»§ ngá»¯ áº©n hoáº·c Reference (VÃ­ dá»¥: Thay vÃ¬ "Regarding A, it increased...", hÃ£y viáº¿t "A, conversely, witnessed a rise...").
*   **>> NGUYÃŠN Táº®C LINH HOáº T CC:** Náº¿u bÃ i viáº¿t cÃ³ logic tá»‘t vÃ  dá»… hiá»ƒu, viá»‡c sá»­ dá»¥ng tá»« ná»‘i hÆ¡i mÃ¡y mÃ³c (nhÆ° "Regarding") KHÃ”NG NÃŠN kÃ©o Ä‘iá»ƒm xuá»‘ng 7.0 ngay láº­p tá»©c. HÃ£y cÃ¢n nháº¯c Band 8.0 náº¿u dÃ²ng cháº£y thÃ´ng tin (flow) váº«n mÆ°á»£t mÃ . Chá»‰ háº¡ xuá»‘ng 7.0 náº¿u viá»‡c dÃ¹ng tá»« ná»‘i gÃ¢y khÃ³ chá»‹u hoáº·c lÃ m giÃ¡n Ä‘oáº¡n viá»‡c Ä‘á»c.
*   **>> YÃŠU Cáº¦U OUTPUT CHO PHáº¦N NÃ€Y:**
    *   **TrÃ­ch dáº«n chá»©ng:** Pháº£i trÃ­ch dáº«n cÃ¢u vÄƒn cá»¥ thá»ƒ cá»§a thÃ­ sinh Ä‘á»ƒ phÃ¢n tÃ­ch.
    *   **Gá»£i Ã½ "Vá»«a sá»©c":** 
        *   BÃ i dÆ°á»›i Band 7 -> Gá»£i Ã½ sá»­a cho ÄÃšNG.
        *   BÃ i Band 7+ -> Gá»£i Ã½ sá»­a cho HAY (Band 9).
#### C. Lexical Resource (LR)
*   **Naturalness over Academic:** Æ¯u tiÃªn tá»« vá»±ng tá»± nhiÃªn (use, help, start) hÆ¡n lÃ  tá»« Ä‘ao to bÃºa lá»›n sai ngá»¯ cáº£nh (utilise, facilitate, commence).
*   **Blacklist:** Cáº£nh bÃ¡o cÃ¡c tá»« sÃ¡o rá»—ng/há»c thuá»™c lÃ²ng bá»‹ láº¡m dá»¥ng.
*   **Precision:** Soi ká»¹ Collocation (VD: "increased significantly" > "increased strongly").
*   **>> Bá»” SUNG QUY Táº®C "REPETITION" (Láº·p tá»«):**
        *   Náº¿u má»™t tá»« vá»±ng quan trá»ng (vÃ­ dá»¥: "increase", "fluctuate") bá»‹ láº·p láº¡i > 3 láº§n mÃ  khÃ´ng cÃ³ ná»— lá»±c thay tháº¿ (paraphrase) -> **Tá»I ÄA BAND 5.0 LR** (Lá»—i "Limited flexibility").
    *   **>> QUY Táº®C CHÃNH Táº¢ (Spelling Threshold):**
        *   Sai 1-2 lá»—i nhá» -> Váº«n cÃ³ thá»ƒ Band 8.
        *   Sai vÃ i lá»—i (A few) nhÆ°ng váº«n hiá»ƒu Ä‘Æ°á»£c -> Band 7.
        *   Sai nhiá»u lá»—i (Noticeable) nhÆ°ng váº«n hiá»ƒu Ä‘Æ°á»£c -> Band 6.
        *   Sai gÃ¢y khÃ³ hiá»ƒu (Impede meaning) -> Band 5.
*   **>> NGUYÃŠN Táº®C "NO DOUBLE PENALIZATION" (KhÃ´ng pháº¡t kÃ©p):**
        *   Náº¿u lá»—i thuá»™c vá» Redundancy (thá»«a tá»«: *most highest*) hoáº·c Spelling (*fluctation*), hÃ£y tÃ­nh nÃ³ vÃ o Ä‘iá»ƒm Lexical Resource (LR).
        *   KHÃ”NG trá»« Ä‘iá»ƒm Grammatical Range (GRA) cho nhá»¯ng lá»—i Ä‘Ã£ tÃ­nh á»Ÿ LR, trá»« khi nÃ³ lÃ m sai cáº¥u trÃºc cÃ¢u nghiÃªm trá»ng. ÄÃ¢y lÃ  lÃ½ do táº¡i sao má»™t bÃ i cÃ³ lá»—i tá»« vá»±ng váº«n cÃ³ thá»ƒ Ä‘áº¡t 9.0 GRA náº¿u cáº¥u trÃºc cÃ¢u phá»©c táº¡p vÃ  Ä‘a dáº¡ng.
*   **Word Choice:** Æ¯u tiÃªn "Proportion" cho dá»¯ liá»‡u nhÃ¢n lá»±c/dÃ¢n sá»‘. "Percentage" chá»‰ lÃ  con sá»‘ thuáº§n tÃºy.
*   **Precision:** "Chosen one" -> Sai style. Sá»­a thÃ nh "Popular sector".
#### D. Grammatical Range & Accuracy (GRA)
*   **Äá»™ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i:** Soi ká»¹ tá»«ng lá»—i máº¡o tá»«, giá»›i tá»«, sá»‘ Ã­t/nhiá»u.
*   **Tá»· lá»‡ cÃ¢u khÃ´ng lá»—i (Error-free sentences):**
    *   Band 6: CÃ³ lá»—i nhÆ°ng khÃ´ng quÃ¡ khÃ³ hiá»ƒu.
    *   Band 7: CÃ¢u khÃ´ng lá»—i xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn (Frequent).
    *   Band 8+: Äa sá»‘ cÃ¡c cÃ¢u hoÃ n toÃ n sáº¡ch lá»—i (Majority error-free).
*   **CÃ¡c lá»—i ká»¹ thuáº­t:**
    *   **Comma Splice:** DÃ¹ng dáº¥u pháº©y ná»‘i hai má»‡nh Ä‘á» Ä‘á»™c láº­p -> KÃ©o Ä‘iá»ƒm xuá»‘ng Band 5-6.
    *   **The Mad Max:** Láº¡m dá»¥ng hoáº·c thiáº¿u máº¡o tá»« "the".
    *   **Past Perfect Trigger:** Tháº¥y "By + [thá»i gian quÃ¡ khá»©]" mÃ  khÃ´ng dÃ¹ng QuÃ¡ khá»© hoÃ n thÃ nh -> ÄÃ¡nh dáº¥u yáº¿u kÃ©m vá» Range.
    *   **>> Bá»” SUNG QUY Táº®C Dáº¤U CÃ‚U (Punctuation Control):** NgoÃ i Comma Splice, náº¿u bÃ i viáº¿t thÆ°á»ng xuyÃªn thiáº¿u dáº¥u pháº©y ngÄƒn cÃ¡ch má»‡nh Ä‘á» phá»¥ (Subordinate clause), hoáº·c viáº¿t hoa tÃ¹y tiá»‡n -> **KHÃ”NG ÄÆ¯á»¢C CHáº¤M BAND 8.0 GRA**.
*   **>> CHIáº¾N THUáº¬T PARAPHRASING (Introduction Strategy):**
        *   Kiá»ƒm tra cÃ¢u má»Ÿ Ä‘áº§u (Introduction). Náº¿u thÃ­ sinh chá»‰ thay tá»« Ä‘á»“ng nghÄ©a (synonyms) trong cá»¥m danh tá»« (Noun Phrase), hÃ£y Ä‘Ã¡nh giÃ¡ á»Ÿ má»©c "Standard".
        *   Náº¿u thÃ­ sinh chuyá»ƒn Ä‘á»•i Ä‘Æ°á»£c cáº¥u trÃºc tá»« Noun Phrase (*the number of...*) sang Noun Clause (*how many...*), hÃ£y ghi nháº­n Ä‘Ã¢y lÃ  Ä‘iá»ƒm cá»™ng lá»›n cho Band 8+ GRA.
*   **Band 9 Threshold:** Náº¿u bÃ i viáº¿t dÃ¹ng cÃ¢u phá»©c hay vÃ  tá»± nhiÃªn, cho phÃ©p 1-2 lá»—i nhá» (slips). Äá»«ng káº¹t á»Ÿ Band 8.0 chá»‰ vÃ¬ má»™t lá»—i máº¡o tá»«.
*   **>> NGUYÃŠN Táº®C "SLIPS" TRONG GRA:** Band 9.0 GRA cho phÃ©p "rare minor errors" (cÃ¡c lá»—i nhá» hiáº¿m gáº·p). Náº¿u bÃ i viáº¿t sá»­ dá»¥ng nhiá»u cáº¥u trÃºc phá»©c táº¡p má»™t cÃ¡ch tá»± nhiÃªn, Ä‘á»«ng ngáº§n ngáº¡i cho 9.0 dÃ¹ váº«n cÃ²n 1-2 lá»—i máº¡o tá»« hoáº·c sá»‘ Ã­t/nhiá»u. Äá»«ng mÃ¡y mÃ³c cháº·n á»Ÿ 8.0.
*   **>> GIAO THá»¨C "PREPOSITION MICRO-SCANNING" (Soi Giá»›i tá»« Cháº¿t ngÆ°á»i):**
    *   Sau khi quÃ©t toÃ n bá»™ bÃ i viáº¿t, hÃ£y thá»±c hiá»‡n má»™t lÆ°á»£t quÃ©t **thá»© hai** chá»‰ Ä‘á»ƒ tÃ¬m lá»—i giá»›i tá»« Ä‘i kÃ¨m vá»›i sá»‘ liá»‡u vÃ  xu hÆ°á»›ng.
    *   **To:** DÃ¹ng cho Ä‘iá»ƒm Ä‘áº¿n cuá»‘i cÃ¹ng (VD: "recovered **to** 15%").
    *   **At:** DÃ¹ng cho má»™t Ä‘iá»ƒm cá»‘ Ä‘á»‹nh (VD: "stood **at** 10%").
    *   **Of:** DÃ¹ng Ä‘á»ƒ chá»‰ giÃ¡ trá»‹ cá»§a má»™t danh tá»« (VD: "a level **of** 15%").
    *   **In:** DÃ¹ng cho nÄƒm (VD: "**in** 2015").
    *   **By:** DÃ¹ng Ä‘á»ƒ chá»‰ má»™t lÆ°á»£ng thay Ä‘á»•i (VD: "decreased **by** 5%").
    *   **Báº®T BUá»˜C:** Náº¿u thÃ­ sinh dÃ¹ng sai báº¥t ká»³ giá»›i tá»« nÃ o trong cÃ¡c trÆ°á»ng há»£p trÃªn (vÃ­ dá»¥: dÃ¹ng "at" hoáº·c "by" thay vÃ¬ "to"), hÃ£y báº¯t lá»—i **"Preposition Error"** vÃ  giáº£i thÃ­ch rÃµ quy táº¯c sá»­ dá»¥ng. ÄÃ¢y lÃ  lá»—i cÆ¡ báº£n nhÆ°ng lÃ m máº¥t Ä‘iá»ƒm ráº¥t náº·ng.
    
### 3. QUY TRÃŒNH CHáº¤M ÄIá»‚M & Tá»° Sá»¬A Lá»–I (SCORING & SELF-CORRECTION)

Má»i tá»« hoáº·c dáº¥u cÃ¢u náº±m trong tháº» `<del>...</del>` á»Ÿ báº£n sá»­a **Báº®T BUá»˜C** pháº£i cÃ³ má»™t má»¥c nháº­p (entry) riÃªng biá»‡t tÆ°Æ¡ng á»©ng trong danh sÃ¡ch `errors`. Tuyá»‡t Ä‘á»‘i khÃ´ng Ä‘Æ°á»£c tÃ³m táº¯t hay gá»™p lá»—i.
**BÆ°á»›c 1: Deep Scan & Láº­p danh sÃ¡ch lá»—i (JSON Errors Array)**
**BÆ°á»›c 2: Táº¡o báº£n sá»­a lá»—i (Annotated Essay)**
**BÆ°á»›c 3: Cháº¥m láº¡i báº£n sá»­a lá»—i (JSON Output - Internal Re-grading)**

YÃŠU Cáº¦U OUTPUT LÃ€ Má»˜T JSON OBJECT DUY NHáº¤T chá»©a dá»¯ liá»‡u dÆ°á»›i Ä‘Ã¢y. 
Tuyá»‡t Ä‘á»‘i KHÃ”NG tráº£ vá» markdown bÃªn ngoÃ i JSON. Má»i phÃ¢n tÃ­ch chá»¯ viáº¿t pháº£i náº±m trong cÃ¡c trÆ°á»ng "analysis" cá»§a JSON.

```json
{
  "original_score": {
      "task_achievement": "Äiá»ƒm TA",
      "cohesion_coherence": "Äiá»ƒm CC",
      "lexical_resource": "Äiá»ƒm LR",
      "grammatical_range": "Äiá»ƒm GRA",
      "overall": "Äiá»ƒm Overall"
  },
  "detailed_analysis": {
      "task_achievement": "VIáº¾T PHÃ‚N TÃCH CHI TIáº¾T TA VÃ€O ÄÃ‚Y (Markdown allowed, >200 tá»«)",
      "cohesion_coherence": "VIáº¾T PHÃ‚N TÃCH CHI TIáº¾T CC VÃ€O ÄÃ‚Y (Markdown allowed, >200 tá»«)",
      "lexical_resource": "VIáº¾T PHÃ‚N TÃCH CHI TIáº¾T LR VÃ€O ÄÃ‚Y (Markdown allowed, >200 tá»«)",
      "grammatical_range": "VIáº¾T PHÃ‚N TÃCH CHI TIáº¾T GRA VÃ€O ÄÃ‚Y (Markdown allowed, >200 tá»«)"
  },
  "errors": [
    {
      "category": "Grammar" hoáº·c "Vocabulary",
      "type": "TÃªn Lá»—i",
      "impact_level": "High" | "Medium" | "Low",
      "explanation": "Giáº£i thÃ­ch ngáº¯n gá»n lá»—i.",
      "original": "Ä‘oáº¡n vÄƒn báº£n sai",
      "correction": "Ä‘oáº¡n vÄƒn báº£n Ä‘Ãºng (VIáº¾T IN HOA)"
    }
  ],
  "annotated_essay": "PhiÃªn báº£n bÃ i lÃ m Ä‘Ã£ Ä‘Æ°á»£c sá»­a lá»—i...",
   "revised_score": {
      "task_achievement": "Äiá»ƒm TA sau sá»­a",
      "cohesion_coherence": "Äiá»ƒm CC sau sá»­a",
      "lexical_resource": "Äiá»ƒm LR sau sá»­a",
      "grammatical_range": "Äiá»ƒm GRA sau sá»­a",
      "overall": "Äiá»ƒm Overall sau sá»­a",
      "logic_re_evaluation": "Giáº£i thÃ­ch..."
  }
}
```
"""

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def clean_json(text):
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if match: return match.group(1).strip()
    if text.strip().startswith("{"): return text.strip()
    return None

def parse_guide_response(text):
    try:
        j_str = clean_json(text)
        return json.loads(j_str) if j_str else None
    except: return None

def parse_grading_response(full_text):
    """
    HÃ m Deep Search: QuÃ©t toÃ n bá»™ cáº¥u trÃºc JSON Ä‘á»ƒ tÃ¬m ná»™i dung phÃ¢n tÃ­ch
    báº¥t ká»ƒ AI giáº¥u nÃ³ á»Ÿ Ä‘Ã¢u (root, detailed_analysis, gap_analysis...)
    """
    json_str = clean_json(full_text)
    data = {"errors": [], "annotatedEssay": None, "revisedScore": None, "originalScore": {}, "analysisMarkdown": ""}
    
    if json_str:
        try:
            parsed = json.loads(json_str)
            data.update(parsed)
            data["originalScore"] = parsed.get("original_score", {})
            data["annotatedEssay"] = parsed.get("annotated_essay")
            data["revisedScore"] = parsed.get("revised_score")
            
            # --- LOGIC DEEP SEARCH (QUÃ‰T SÃ‚U) ---
            sections = []
            
            # 1. Äá»‹nh nghÄ©a cÃ¡c nguá»“n dá»¯ liá»‡u tiá»m nÄƒng
            sources_to_check = [
                parsed,                                      # Root object
                parsed.get("detailed_analysis", {}),         # Key tiÃªu chuáº©n
                parsed.get("original_score", {}),            # AI hay nháº§m nhÃ©t vÃ o Ä‘Ã¢y
                parsed.get("analysis", {})                   # Má»™t key phá»• biáº¿n khÃ¡c
            ]

            # 2. Äá»‹nh nghÄ©a tá»« khÃ³a nháº­n diá»‡n cho 4 tiÃªu chÃ­
            criteria_keywords = {
                "Task Achievement": ["task_achievement", "ta_gap", "ta_analysis", "task_response", "achievement"],
                "Coherence & Cohesion": ["cohesion", "cc_gap", "cc_analysis", "linking", "coherence"],
                "Lexical Resource": ["lexical", "lr_gap", "lr_analysis", "vocabulary", "lexical_resource"],
                "Grammatical Range": ["grammatical", "gra_gap", "gra_analysis", "grammar", "grammatical_range"]
            }

            found_keys = set() # TrÃ¡nh in trÃ¹ng láº·p

            for title, keywords in criteria_keywords.items():
                content_found = None
                
                # Duyá»‡t qua tá»«ng nguá»“n dá»¯ liá»‡u
                for source in sources_to_check:
                    if not isinstance(source, dict): continue
                    
                    for k, v in source.items():
                        # Äiá»u kiá»‡n chá»n: Key chá»©a tá»« khÃ³a VÃ€ Value lÃ  text dÃ i (>50 kÃ½ tá»±)
                        if any(kw in k.lower() for kw in keywords) and isinstance(v, str) and len(v) > 50:
                            if k not in found_keys:
                                content_found = v
                                found_keys.add(k) # ÄÃ¡nh dáº¥u Ä‘Ã£ dÃ¹ng
                                break
                    if content_found: break 
                
                if content_found:
                    sections.append(f"### ğŸ“˜ {title}\n{content_found}")

            # 3. GhÃ©p káº¿t quáº£
            if sections:
                data["analysisMarkdown"] = "\n\n".join(sections)
            
            # 4. Fallback: Náº¿u Deep Search tháº¥t báº¡i, thá»­ láº¥y key tá»•ng
            elif parsed.get("analysis_markdown"):
                data["analysisMarkdown"] = parsed["analysis_markdown"]

        except Exception as e:
            data["analysisMarkdown"] = full_text.split("```json")[0]
            
    # Fallback cuá»‘i cÃ¹ng
    if not data["analysisMarkdown"] or len(data["analysisMarkdown"]) < 20:
        if json_str:
             display_json = {k:v for k,v in parsed.items() if k not in ['annotated_essay', 'errors']} if 'parsed' in locals() else json_str
             data["analysisMarkdown"] = f"âš ï¸ **AI tráº£ vá» Ä‘á»‹nh dáº¡ng láº¡.** DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung thÃ´ tÃ¬m Ä‘Æ°á»£c:\n\n```json\n{json.dumps(display_json, indent=2, ensure_ascii=False)}\n```"
        else:
             data["analysisMarkdown"] = full_text

    return data

def register_vietnamese_font():
    try:
        font_reg = "Roboto-Regular.ttf"
        font_bold = "Roboto-Bold.ttf"
        if not os.path.exists(font_reg):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf")
            with open(font_reg, "wb") as f: f.write(r.content)
        if not os.path.exists(font_bold):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Bold.ttf")
            with open(font_bold, "wb") as f: f.write(r.content)
        pdfmetrics.registerFont(TTFont('Roboto', font_reg))
        pdfmetrics.registerFont(TTFont('Roboto-Bold', font_bold))
        addMapping('Roboto', 0, 0, 'Roboto')
        addMapping('Roboto', 1, 0, 'Roboto-Bold')
        return True
    except: return False

def create_docx(data, topic, essay, analysis):
    doc = Document()
    doc.add_heading('IELTS ASSESSMENT REPORT', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_heading('1. DETAILED ANALYSIS', level=1)
    doc.add_paragraph(analysis)
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def create_pdf(data, topic, essay, analysis):
    register_vietnamese_font()
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    elements = [Paragraph("IELTS ASSESSMENT REPORT", styles['Title'])]
    elements.append(Paragraph("DETAILED ANALYSIS", styles['Heading1']))
    safe_text = html.escape(analysis).replace('\n', '<br/>')
    elements.append(Paragraph(safe_text, styles['Normal']))
    doc.build(elements)
    buffer.seek(0)
    return buffer

# ==========================================
# 4. UI: SESSION STATE INIT
# ==========================================
if "step" not in st.session_state: st.session_state.step = 1 
if "guide_data" not in st.session_state: st.session_state.guide_data = None
if "grading_result" not in st.session_state: st.session_state.grading_result = None
if "saved_topic" not in st.session_state: st.session_state.saved_topic = ""
if "saved_img" not in st.session_state: st.session_state.saved_img = None

# ==========================================
# 5. UI: PHASE 1 - INPUT & GUIDE
# ==========================================
st.title("ğŸ“ IELTS Writing: Learn & Grade")

if st.session_state.step == 1:
    col1, col2 = st.columns([1, 1])
    with col1:
        st.subheader("1. Äá» bÃ i")
        question_input = st.text_area("Nháº­p cÃ¢u há»i:", height=150, placeholder="The chart below shows...", key="q_input")

    with col2:
        st.subheader("2. HÃ¬nh áº£nh")
        uploaded_image = st.file_uploader("Táº£i áº£nh biá»ƒu Ä‘á»“", type=['png', 'jpg', 'jpeg'], key="img_input")
        img_data = Image.open(uploaded_image) if uploaded_image else None
        if img_data: st.image(img_data, caption='Äá» bÃ i', use_container_width=True)

    if st.button("ğŸš€ PhÃ¢n tÃ­ch & HÆ°á»›ng dáº«n", type="primary"):
        if not question_input and not img_data:
            st.warning("Vui lÃ²ng nháº­p Ä‘á» bÃ i hoáº·c áº£nh.")
        else:
            st.session_state.saved_topic = question_input
            st.session_state.saved_img = img_data
            
            with st.spinner("AI Ä‘ang phÃ¢n tÃ­ch chiáº¿n thuáº­t..."):
                prompt_guide = """
                PhÃ¢n tÃ­ch Ä‘á» bÃ i IELTS Writing Task 1. Tráº£ vá» JSON:
                { "task_type": "...", "intro_guide": "...", "overview_guide": "...", "body1_guide": "...", "body2_guide": "..." }
                Viáº¿t hÆ°á»›ng dáº«n chi tiáº¿t báº±ng tiáº¿ng Viá»‡t.
                """
                res, _ = generate_content_with_failover(prompt_guide + "\n" + question_input, img_data, json_mode=True)
                if res:
                    data = parse_guide_response(res.text)
                    if data:
                        st.session_state.guide_data = data
                        st.session_state.step = 2
                        st.rerun()

# ==========================================
# 6. UI: PHASE 2 - WRITING PRACTICE
# ==========================================
if st.session_state.step == 2 and st.session_state.guide_data:
    data = st.session_state.guide_data
    st.markdown("---")
    st.success(f"ğŸ“Œ Loáº¡i bÃ i: **{data.get('task_type', 'Task 1')}**")
    
    st.markdown("### âœï¸ Thá»±c hÃ nh viáº¿t bÃ i")
    
    def render_input(title, guide, key):
        st.markdown(f"**{title}**")
        with st.expander(f"ğŸ’¡ Xem gá»£i Ã½", expanded=False):
            st.markdown(f"<div class='guide-box'>{guide}</div>", unsafe_allow_html=True)
        return st.text_area(f"Nháº­p {title}:", height=150, key=key)

    c1, c2 = st.columns(2)
    with c1:
        intro = render_input("Introduction", data.get("intro_guide"), "in_intro")
        body1 = render_input("Body 1", data.get("body1_guide"), "in_body1")
    with c2:
        over = render_input("Overview", data.get("overview_guide"), "in_overview")
        body2 = render_input("Body 2", data.get("body2_guide"), "in_body2")

    full_essay = f"{intro}\n\n{over}\n\n{body1}\n\n{body2}".strip()
    wc = len(full_essay.split())
    st.caption(f"ğŸ“Š Sá»‘ tá»«: {wc}")

    st.markdown("---")
    if st.button("âœ¨ Gá»­i cháº¥m Ä‘iá»ƒm (Examiner Pro Mode)", type="primary", use_container_width=True):
        if wc < 20:
            st.warning("BÃ i viáº¿t quÃ¡ ngáº¯n.")
        else:
            status = st.status("ğŸ‘¨â€ğŸ« Examiner Ä‘ang cháº¥m bÃ i...", expanded=True)
            status.write("ğŸ” QuÃ©t lá»—i ngá»¯ phÃ¡p & Logic...")
            
            prompt_grade = GRADING_PROMPT_TEMPLATE.replace('{{TOPIC}}', st.session_state.saved_topic).replace('{{ESSAY}}', full_essay)
            
            res_grade, _ = generate_content_with_failover(prompt_grade, st.session_state.saved_img, json_mode=True)
            
            status.write("ğŸ“ Tá»•ng há»£p bÃ¡o cÃ¡o...")
            if res_grade:
                p_data = parse_grading_response(res_grade.text)
                st.session_state.grading_result = {
                    "data": p_data, "essay": full_essay, "topic": st.session_state.saved_topic
                }
                st.session_state.step = 3
                status.update(label="âœ… ÄÃ£ cháº¥m xong!", state="complete", expanded=False)
                st.rerun()
            else:
                status.update(label="âŒ AI Äang báº­n, vui lÃ²ng thá»­ láº¡i!", state="error")

# ==========================================
# 7. UI: PHASE 3 - GRADING RESULT (EXAMINER UI)
# ==========================================
if st.session_state.step == 3 and st.session_state.grading_result:
    res = st.session_state.grading_result
    g_data = res["data"]
    
    st.markdown("## ğŸ›¡ï¸ Káº¾T QUáº¢ ÄÃNH GIÃ CHI TIáº¾T")
    
    # 1. Báº£ng Ä‘iá»ƒm Gá»‘c
    scores = g_data.get("originalScore", {})
    st.markdown("### ğŸ“Š Äiá»ƒm sá»‘ hiá»‡n táº¡i")
    cols = st.columns(5)
    cols[0].metric("Task Achievement", scores.get("task_achievement", "-"))
    cols[1].metric("Coherence", scores.get("cohesion_coherence", "-"))
    cols[2].metric("Lexical", scores.get("lexical_resource", "-"))
    cols[3].metric("Grammar", scores.get("grammatical_range", "-"))
    cols[4].metric("OVERALL", scores.get("overall", "-"))
    
    st.markdown("---")

    # 2. Tabs Chi tiáº¿t
    tab_analysis, tab_errors, tab_macro, tab_annotated = st.tabs([
        "ğŸ“ PhÃ¢n tÃ­ch 4 TiÃªu chÃ­", 
        "ğŸ”´ Lá»—i Ngá»¯ phÃ¡p/Tá»« vá»±ng", 
        "ğŸ”µ Lá»—i Máº¡ch láº¡c/Logic",
        "âœï¸ BÃ i sá»­a (Annotated)"
    ])
    
    with tab_analysis:
        st.info("DÆ°á»›i Ä‘Ã¢y lÃ  nháº­n xÃ©t chi tiáº¿t cá»§a GiÃ¡m kháº£o cho tá»«ng tiÃªu chÃ­:")
        analysis_content = g_data.get("analysisMarkdown", "")
        if analysis_content:
            st.markdown(analysis_content)
        else:
            st.warning("KhÃ´ng tÃ¬m tháº¥y ná»™i dung phÃ¢n tÃ­ch chi tiáº¿t.")

    with tab_errors:
        errors = g_data.get("errors", [])
        micro = [e for e in errors if e.get('category') in ['Grammar', 'Vocabulary', 'Ngá»¯ phÃ¡p', 'Tá»« vá»±ng']]
        if not micro: st.success("KhÃ´ng tÃ¬m tháº¥y lá»—i ngá»¯ phÃ¡p Ä‘Ã¡ng ká»ƒ.")
        for i, err in enumerate(micro):
            badge = "#DCFCE7" if err.get('category') in ['Grammar','Ngá»¯ phÃ¡p'] else "#FEF9C3"
            st.markdown(f"""
            <div class="error-card">
                <div style="display:flex; justify-content:space-between; margin-bottom:5px;">
                    <span><b>#{i+1} [{err.get('category')}]</b>: {err.get('type')}</span>
                    <span style="background:#eee; padding:2px 8px; border-radius:10px; font-size:0.8em">{err.get('impact_level')}</span>
                </div>
                <div style="background:{badge}; padding:8px; border-radius:5px; margin-bottom:5px;">
                    <s>{err.get('original')}</s> â” <b>{err.get('correction')}</b>
                </div>
                <small><i>{err.get('explanation')}</i></small>
            </div>
            """, unsafe_allow_html=True)

    with tab_macro:
        macro = [e for e in errors if e.get('category') not in ['Grammar', 'Vocabulary', 'Ngá»¯ phÃ¡p', 'Tá»« vá»±ng']]
        if not macro: st.success("Cáº¥u trÃºc máº¡ch láº¡c tá»‘t.")
        for err in macro:
            st.markdown(f"""
            <div class="error-card" style="border-left: 5px solid #3B82F6;">
                <b>[{err.get('category')}] {err.get('type')}</b><br>
                Váº¥n Ä‘á»: {err.get('explanation')}<br>
                Gá»£i Ã½: <b>{err.get('correction')}</b>
            </div>
            """, unsafe_allow_html=True)

    with tab_annotated:
        st.markdown(f'<div class="annotated-text">{g_data.get("annotatedEssay", "")}</div>', unsafe_allow_html=True)

    # 3. Revised Score
    st.markdown("---")
    st.subheader("ğŸ“ˆ Dá»± bÃ¡o Ä‘iá»ƒm sau khi sá»­a lá»—i (Revised Score)")
    
    rev = g_data.get("revisedScore", {})
    if rev:
        r_cols = st.columns(5)
        r_cols[0].metric("TA (Rev)", rev.get("task_achievement", "-"))
        r_cols[1].metric("CC (Rev)", rev.get("cohesion_coherence", "-"))
        r_cols[2].metric("LR (Rev)", rev.get("lexical_resource", "-"))
        r_cols[3].metric("GRA (Rev)", rev.get("grammatical_range", "-"))
        r_cols[4].metric("OVERALL (Rev)", rev.get("overall", "-"))
        
        if rev.get("logic_re_evaluation"):
            st.info(f"ğŸ’¡ **LÆ°u Ã½ cá»§a GiÃ¡m kháº£o:** {rev.get('logic_re_evaluation')}")
    else:
        st.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘iá»ƒm dá»± bÃ¡o.")

    # 4. Export Buttons
    st.markdown("---")
    d1, d2 = st.columns(2)
    
    full_report_text = g_data.get("analysisMarkdown", "")
    
    docx = create_docx(g_data, res['topic'], res['essay'], full_report_text)
    d1.download_button("ğŸ“„ Download Report (.docx)", docx, "IELTS_Report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
    
    pdf = create_pdf(g_data, res['topic'], res['essay'], full_report_text)
    d2.download_button("ğŸ“• Download Report (.pdf)", pdf, "IELTS_Report.pdf", "application/pdf", use_container_width=True)
    
    if st.button("ğŸ”„ LÃ m bÃ i má»›i (Reset)", use_container_width=True):
        st.session_state.step = 1
        st.session_state.guide_data = None
        st.session_state.grading_result = None
        st.session_state.saved_topic = ""
        st.session_state.saved_img = None
        st.rerun()
