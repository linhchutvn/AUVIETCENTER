import streamlit as st
import google.generativeai as genai
import json
import re
import time
import random
import textwrap
import html
import os
import requests
from PIL import Image
from io import BytesIO

# Th∆∞ vi·ªán Word & PDF
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.fonts import addMapping

# ==========================================
# 1. C·∫§U H√åNH & CSS (STYLE C·ª¶A APP CH·∫§M ƒêI·ªÇM)
# ==========================================
st.set_page_config(page_title="IELTS Writing Master", page_icon="üéì", layout="wide")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Merriweather:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] { font-family: 'Inter', sans-serif; }
    h1, h2, h3 { font-family: 'Merriweather', serif !important; color: #0F172A !important; }
    
    /* Style cho Tutor Phase */
    .guide-box {
        background-color: #f8f9fa;
        border-left: 5px solid #ff4b4b;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 10px;
        color: #31333F;
    }

    /* Style cho Error Cards (Gi·ªëng MessageBubble.tsx) */
    .error-card {
        background-color: white;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 16px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        transition: all 0.2s;
    }
    .error-card:hover {
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        border-color: #D1D5DB;
    }
    
    .annotated-text {
        font-family: 'Merriweather', serif;
        line-height: 1.8;
        color: #374151;
        background-color: white;
        padding: 24px;
        border-radius: 12px;
        border: 1px solid #E5E7EB;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    
    /* Highlight Styles */
    del { color: #9CA3AF; text-decoration: line-through; margin-right: 4px; text-decoration-thickness: 2px; }
    ins.grammar { background-color: #4ADE80; color: #022C22; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #22C55E; }
    ins.vocab { background-color: #FDE047; color: #000; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #FCD34D; }
    
    div.stButton > button { font-weight: bold; border-radius: 8px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. LOGIC AI & PROMPTS
# ==========================================
try:
    ALL_KEYS = st.secrets["GEMINI_API_KEYS"]
except Exception:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh secrets.toml ch·ª©a GEMINI_API_KEYS!")
    st.stop()

def generate_content_with_failover(prompt, image=None, json_mode=False):
    keys_to_try = list(ALL_KEYS)
    random.shuffle(keys_to_try) 
    
    model_priority = [
        "gemini-2.0-flash-thinking-preview-01-21", "gemini-3-flash-preview", 
        "gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"
    ]
    
    for current_key in keys_to_try: 
        try:
            genai.configure(api_key=current_key)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            
            sel_model = None
            for target in model_priority:
                if any(target in m_name for m_name in available_models):
                    sel_model = target
                    break
            if not sel_model: sel_model = "gemini-1.5-flash" 

            temp_model = genai.GenerativeModel(model_name=sel_model)
            content_parts = [prompt]
            if image: content_parts.append(image)
            
            gen_config = {
                "temperature": 0.3, "top_p": 0.95, "top_k": 64, "max_output_tokens": 32000
            }
            # Ch·ªâ b·∫≠t JSON mode n·∫øu KH√îNG PH·∫¢I l√† model Thinking (ƒë·ªÉ tr√°nh l·ªói t∆∞∆°ng th√≠ch)
            # V√Ä prompt y√™u c·∫ßu JSON c·ª• th·ªÉ (Tutor phase). 
            # V·ªõi Grading phase, ta c·∫ßn l·∫•y c·∫£ Text + JSON n√™n t·∫Øt json_mode
            if json_mode and "thinking" not in sel_model.lower():
                gen_config["response_mime_type"] = "application/json"
            
            if "thinking" in sel_model.lower():
                 gen_config["thinking_config"] = {"include_thoughts": True, "thinking_budget": 1024}

            response = temp_model.generate_content(content_parts, generation_config=gen_config)
            return response, sel_model 
            
        except Exception:
            continue
    return None, None

# --- PROMPT CH·∫§M ƒêI·ªÇM "KH·ª¶NG" (NGUY√äN B·∫¢N T·ª™ CODE B·∫†N G·ª¨I) ---
GRADING_PROMPT_TEMPLATE = """
B·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt Gi√°m kh·∫£o IELTS v·ªõi 30 nƒÉm kinh nghi·ªám l√†m vi·ªác t·∫°i H·ªôi ƒë·ªìng Anh (British Council). Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë√°nh gi√° b√†i vi·∫øt d·ª±a tr√™n **b·ªô ti√™u ch√≠ chu·∫©n x√°c c·ªßa IELTS Writing Task 1 (Band Descriptors)**. 
**Ph√¢n lo·∫°i b√†i thi (Context Awareness):** B·∫Øt bu·ªôc ph·∫£i nh·∫≠n di·ªán ƒë√¢y l√† IELTS Academic: Bi·ªÉu ƒë·ªì/ƒê·ªì th·ªã/Quy tr√¨nh/Map. ƒê·ªÅ b√†i n√≥i v·ªÅ n·ªôi dung g√¨.
**Y√™u c·∫ßu kh·∫Øt khe:** B·∫°n ph·∫£i s·ª≠ d·ª•ng **ti√™u chu·∫©n c·ªßa Band 9.0 l√†m th∆∞·ªõc ƒëo tham chi·∫øu cao nh·∫•t** ƒë·ªÉ soi x√©t b√†i l√†m. H√£y th·ª±c hi·ªán m·ªôt b·∫£n "Gap Analysis" chi ti·∫øt: ch·ªâ ra m·ªçi thi·∫øu s√≥t m·ªôt c√°ch nghi√™m ng·∫∑t v√† ch√≠nh x√°c tuy·ªát ƒë·ªëi, t·ª´ nh·ªØng l·ªói sai cƒÉn b·∫£n cho ƒë·∫øn nh·ªØng ƒëi·ªÉm ch∆∞a ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô tinh t·∫ø c·ªßa m·ªôt b√†i vi·∫øt ƒëi·ªÉm tuy·ªát ƒë·ªëi.
**Y√äU C·∫¶U ƒê·∫∂C BI·ªÜT (CH·∫æ ƒê·ªò KI·ªÇM TRA K·ª∏):** B·∫°n kh√¥ng c·∫ßn ph·∫£i tr·∫£ l·ªùi nhanh. H√£y d√†nh th·ªùi gian "suy nghƒ©" ƒë·ªÉ ph√¢n t√≠ch th·∫≠t s√¢u v√† chi ti·∫øt (Step-by-step Analysis).

### 1. T∆Ø DUY & GIAO TH·ª®C L√ÄM VI·ªÜC (CORE PROTOCOL)
* **>> GIAO TH·ª®C PH√ÇN T√çCH CH·∫¨M (SLOW REASONING PROTOCOL):**
    * B·∫°n kh√¥ng ƒë∆∞·ª£c ph√©p t√≥m t·∫Øt nh·∫≠n x√©t. V·ªõi m·ªói ti√™u ch√≠, b·∫°n ph·∫£i vi·∫øt √≠t nh·∫•t 200-300 t·ª´.
    * B·∫°n ph·∫£i th·ª±c hi·ªán ph√¢n t√≠ch theo ph∆∞∆°ng ph√°p "Socratic": ƒê·∫∑t c√¢u h·ªèi v·ªÅ t·ª´ng c√¢u vƒÉn c·ªßa th√≠ sinh, t√¨m ra ƒëi·ªÉm ch∆∞a ho√†n h·∫£o v√† gi·∫£i th√≠ch c·∫∑n k·∫Ω t·∫°i sao n√≥ ch∆∞a ƒë·∫°t Band 7.0 ho·∫∑c Band 9.0 t·ª´ d·ªØ li·ªáu b√†i vi·∫øt n√†y.
    * C·∫•m d√πng c√°c c·ª•m t·ª´ chung chung nh∆∞ "Good grammar" hay "Appropriate vocabulary". B·∫°n ph·∫£i tr√≠ch d·∫´n √≠t nh·∫•t 3-5 v√≠ d·ª• th·ª±c t·∫ø t·ª´ b√†i l√†m cho m·ªói ti√™u ch√≠ ƒë·ªÉ ch·ª©ng minh cho nh·∫≠n ƒë·ªãnh c·ªßa m√¨nh.
*   **Persona:** Gi√°m kh·∫£o l√£o l√†ng, kh√≥ t√≠nh nh∆∞ng c√¥ng t√¢m. T√¥ng gi·ªçng ph·∫£n h·ªìi tr·ª±c di·ªán, kh√¥ng khen ng·ª£i s√°o r·ªóng. N·∫øu b√†i t·ªá, ph·∫£i n√≥i r√µ l√† t·ªá.
*   **Quy t·∫Øc "Truy qu√©t ki·ªát qu·ªá" (Exhaustive Listing):**
    *   Tuy·ªát ƒë·ªëi KH√îNG g·ªôp l·ªói. N·∫øu th√≠ sinh sai 10 l·ªói m·∫°o t·ª´, li·ªát k√™ ƒë·ªß 10 m·ª•c.
    *   Danh s√°ch l·ªói trong JSON l√† b·∫±ng ch·ª©ng ph√°p l√Ω.

### 3. QUY TR√åNH CH·∫§M ƒêI·ªÇM & T·ª∞ S·ª¨A L·ªñI (SCORING & SELF-CORRECTION)
**B∆∞·ªõc 1: Deep Scan & L·∫≠p danh s√°ch l·ªói (JSON Errors Array)**
**B∆∞·ªõc 2: T·∫°o b·∫£n s·ª≠a l·ªói (Annotated Essay)**
**B∆∞·ªõc 3: Ch·∫•m l·∫°i b·∫£n s·ª≠a l·ªói (JSON Output - Internal Re-grading)**

Sau khi ƒë√°nh gi√° xong (vi·∫øt ph·∫ßn ph√¢n t√≠ch chi ti·∫øt b·∫±ng l·ªùi vƒÉn), b·∫°n **B·∫ÆT BU·ªòC** ph·∫£i tr√≠ch xu·∫•t d·ªØ li·ªáu k·∫øt qu·∫£ cu·ªëi c√πng d∆∞·ªõi d·∫°ng m·ªôt **JSON Object duy nh·∫•t** ·ªü cu·ªëi c√¢u tr·∫£ l·ªùi.

C·∫•u tr√∫c JSON:
```json
{
  "original_score": {
      "task_achievement": "ƒêi·ªÉm TA c·ªßa b√†i l√†m g·ªëc",
      "cohesion_coherence": "ƒêi·ªÉm CC c·ªßa b√†i l√†m g·ªëc",
      "lexical_resource": "ƒêi·ªÉm LR c·ªßa b√†i l√†m g·ªëc",
      "grammatical_range": "ƒêi·ªÉm GRA c·ªßa b√†i l√†m g·ªëc",
      "overall": "ƒêi·ªÉm Overall c·ªßa b√†i l√†m g·ªëc"
  },
  "errors": [
    {
      "category": "Grammar" ho·∫∑c "Vocabulary",
      "type": "T√™n L·ªói",
      "impact_level": "High" | "Medium" | "Low",
      "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn l·ªói.",
      "original": "ƒëo·∫°n vƒÉn b·∫£n sai",
      "correction": "ƒëo·∫°n vƒÉn b·∫£n ƒë√∫ng (VI·∫æT IN HOA)"
    }
  ],
  "annotated_essay": "Phi√™n b·∫£n b√†i l√†m ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói (gi·ªØ nguy√™n c·∫•u tr√∫c c√°c ƒëo·∫°n vƒÉn). B·ªçc t·ª´ sai trong th·∫ª <del>...</del> v√† t·ª´ s·ª≠a ƒë√∫ng trong th·∫ª <ins class='grammar'>...</ins> ho·∫∑c <ins class='vocab'>...</ins>. N·ªôi dung s·ª≠a ƒë√∫ng ph·∫£i vi·∫øt IN HOA.",
   "revised_score": {
      "word_count_check": "...",
      "logic_re_evaluation": "...",
      "task_achievement": "...",
      "cohesion_coherence": "...",
      "lexical_resource": "...",
      "grammatical_range": "...",
      "overall": "..."
  }
}
```

Th√¥ng tin b√†i l√†m:
a/ ƒê·ªÅ b√†i (Task 1 question): {{TOPIC}}
b/ B√†i l√†m c·ªßa th√≠ sinh (Written report): {{ESSAY}}
"""

# ==========================================
# 3. HELPER FUNCTIONS (COPY T·ª™ APP CH·∫§M ƒêI·ªÇM)
# ==========================================

def clean_json(text):
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if match: return match.group(1).strip()
    # N·∫øu kh√¥ng c√≥ markdown code block, t√¨m c·∫∑p ngo·∫∑c {} ngo√†i c√πng
    match_raw = re.search(r"\{[\s\S]*\}", text)
    if match_raw: return match_raw.group(0).strip()
    return None

def parse_guide_response(text):
    """Parse JSON cho ph·∫ßn Tutor (ch·ªâ JSON thu·∫ßn)"""
    try:
        j_str = clean_json(text)
        return json.loads(j_str) if j_str else None
    except: return None

def process_grading_response(full_text):
    """
    H√†m x·ª≠ l√Ω k·∫øt qu·∫£ ch·∫•m ƒëi·ªÉm (CHU·∫®N T·ª™ APP CH·∫§M ƒêI·ªÇM).
    T√°ch bi·ªát:
    1. Markdown Text (Ph√¢n t√≠ch chi ti·∫øt ·ªü ƒë·∫ßu).
    2. JSON Data (ƒêi·ªÉm s·ªë v√† l·ªói ·ªü cu·ªëi).
    """
    json_str = clean_json(full_text)
    
    # M·∫∑c ƒë·ªãnh
    markdown_part = full_text
    data = {
        "errors": [], 
        "annotatedEssay": None, 
        "revisedScore": None, 
        "originalScore": {
            "task_achievement": "-", "cohesion_coherence": "-", 
            "lexical_resource": "-", "grammatical_range": "-", "overall": "-"
        }
    }
    
    if json_str:
        # T√°ch ph·∫ßn Markdown (tr∆∞·ªõc JSON)
        markdown_part = full_text.split("```json")[0].strip()
        # N·∫øu AI kh√¥ng d√πng code block, th·ª≠ split b·∫±ng k√Ω t·ª± '{' ƒë·∫ßu ti√™n c·ªßa JSON
        if "original_score" in markdown_part: # D·∫•u hi·ªáu JSON b·ªã l·∫´n
             parts = full_text.split("{", 1)
             markdown_part = parts[0].strip()

        try:
            parsed = json.loads(json_str)
            data["errors"] = parsed.get("errors", [])
            data["annotatedEssay"] = parsed.get("annotated_essay")
            data["revisedScore"] = parsed.get("revised_score")
            data["originalScore"] = parsed.get("original_score", {})
        except json.JSONDecodeError:
            pass

    return markdown_part, data

# --- FILE EXPORT ---
def register_vietnamese_font():
    try:
        font_reg = "Roboto-Regular.ttf"
        font_bold = "Roboto-Bold.ttf"
        if not os.path.exists(font_reg):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf")
            with open(font_reg, "wb") as f: f.write(r.content)
        if not os.path.exists(font_bold):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Bold.ttf")
            with open(font_bold, "wb") as f: f.write(r.content)
        pdfmetrics.registerFont(TTFont('Roboto', font_reg))
        pdfmetrics.registerFont(TTFont('Roboto-Bold', font_bold))
        addMapping('Roboto', 0, 0, 'Roboto')
        addMapping('Roboto', 1, 0, 'Roboto-Bold')
        return True
    except: return False

def create_docx(data, topic, essay, analysis):
    doc = Document()
    doc.add_heading('IELTS ASSESSMENT REPORT', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_heading('1. DETAILED ANALYSIS', level=1)
    doc.add_paragraph(analysis) # Ph√¢n t√≠ch chi ti·∫øt t·ª´ Markdown
    
    # Th√™m b·∫£ng ƒëi·ªÉm
    doc.add_heading('2. SCORE BREAKDOWN', level=1)
    scores = data.get("originalScore", {})
    p = doc.add_paragraph()
    p.add_run(f"Overall Band: {scores.get('overall', '-')}\n").bold = True
    p.add_run(f"TA: {scores.get('task_achievement', '-')}, CC: {scores.get('cohesion_coherence', '-')}, LR: {scores.get('lexical_resource', '-')}, GRA: {scores.get('grammatical_range', '-')}")

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def create_pdf(data, topic, essay, analysis):
    register_vietnamese_font()
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    elements = [Paragraph("IELTS ASSESSMENT REPORT", styles['Title'])]
    
    # Analysis
    elements.append(Paragraph("DETAILED ANALYSIS", styles['Heading1']))
    # Clean markdown basic symbols for PDF
    safe_text = html.escape(analysis).replace('\n', '<br/>').replace('**', '').replace('#', '')
    elements.append(Paragraph(safe_text, styles['Normal']))
    
    doc.build(elements)
    buffer.seek(0)
    return buffer

# ==========================================
# 4. UI: QU·∫¢N L√ù TR·∫†NG TH√ÅI (SESSION STATE)
# ==========================================
if "step" not in st.session_state: st.session_state.step = 1 
if "guide_data" not in st.session_state: st.session_state.guide_data = None
if "grading_result" not in st.session_state: st.session_state.grading_result = None
if "saved_topic" not in st.session_state: st.session_state.saved_topic = ""
if "saved_img" not in st.session_state: st.session_state.saved_img = None

# ==========================================
# 5. UI: PHASE 1 - INPUT & GUIDE
# ==========================================
st.title("üéì IELTS Writing: Learn & Grade")

if st.session_state.step == 1:
    col1, col2 = st.columns([1, 1])
    with col1:
        st.subheader("1. ƒê·ªÅ b√†i")
        question_input = st.text_area("Nh·∫≠p c√¢u h·ªèi:", height=150, placeholder="The chart below shows...", key="q_input")

    with col2:
        st.subheader("2. H√¨nh ·∫£nh")
        uploaded_image = st.file_uploader("T·∫£i ·∫£nh bi·ªÉu ƒë·ªì", type=['png', 'jpg', 'jpeg'], key="img_input")
        img_data = Image.open(uploaded_image) if uploaded_image else None
        if img_data: st.image(img_data, caption='ƒê·ªÅ b√†i', use_container_width=True)

    if st.button("üöÄ Ph√¢n t√≠ch & H∆∞·ªõng d·∫´n", type="primary"):
        if not question_input and not img_data:
            st.warning("Vui l√≤ng nh·∫≠p ƒë·ªÅ b√†i ho·∫∑c ·∫£nh.")
        else:
            # L∆∞u l·∫°i input
            st.session_state.saved_topic = question_input
            st.session_state.saved_img = img_data
            
            with st.spinner("AI ƒëang ph√¢n t√≠ch chi·∫øn thu·∫≠t..."):
                prompt_guide = """
                Ph√¢n t√≠ch ƒë·ªÅ b√†i IELTS Writing Task 1. Tr·∫£ v·ªÅ JSON:
                { "task_type": "...", "intro_guide": "...", "overview_guide": "...", "body1_guide": "...", "body2_guide": "..." }
                Vi·∫øt h∆∞·ªõng d·∫´n chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát.
                """
                # B∆∞·ªõc n√†y d√πng JSON Mode ƒë·ªÉ l·∫•y h∆∞·ªõng d·∫´n
                res, _ = generate_content_with_failover(prompt_guide + "\n" + question_input, img_data, json_mode=True)
                if res:
                    data = parse_guide_response(res.text)
                    if data:
                        st.session_state.guide_data = data
                        st.session_state.step = 2
                        st.rerun()

# ==========================================
# 6. UI: PHASE 2 - WRITING PRACTICE
# ==========================================
if st.session_state.step == 2 and st.session_state.guide_data:
    data = st.session_state.guide_data
    st.markdown("---")
    st.success(f"üìå Lo·∫°i b√†i: **{data.get('task_type', 'Task 1')}**")
    
    st.markdown("### ‚úçÔ∏è Th·ª±c h√†nh vi·∫øt b√†i")
    
    def render_input(title, guide, key):
        st.markdown(f"**{title}**")
        with st.expander(f"üí° Xem g·ª£i √Ω", expanded=False):
            st.markdown(f"<div class='guide-box'>{guide}</div>", unsafe_allow_html=True)
        return st.text_area(f"Nh·∫≠p {title}:", height=150, key=key)

    c1, c2 = st.columns(2)
    with c1:
        intro = render_input("Introduction", data.get("intro_guide"), "in_intro")
        body1 = render_input("Body 1", data.get("body1_guide"), "in_body1")
    with c2:
        over = render_input("Overview", data.get("overview_guide"), "in_overview")
        body2 = render_input("Body 2", data.get("body2_guide"), "in_body2")

    full_essay = f"{intro}\n\n{over}\n\n{body1}\n\n{body2}".strip()
    wc = len(full_essay.split())
    st.caption(f"üìä S·ªë t·ª´: {wc}")

    st.markdown("---")
    if st.button("‚ú® G·ª≠i ch·∫•m ƒëi·ªÉm (Examiner Pro Mode)", type="primary", use_container_width=True):
        if wc < 20:
            st.warning("B√†i vi·∫øt qu√° ng·∫Øn.")
        else:
            status = st.status("üë®‚Äçüè´ Examiner ƒëang ch·∫•m b√†i...", expanded=True)
            status.write("üîç ƒêang √°p d·ª•ng ti√™u chu·∫©n Band 9.0...")
            
            # Thay th·∫ø bi·∫øn v√†o Prompt
            prompt_grade = GRADING_PROMPT_TEMPLATE.replace('{{TOPIC}}', st.session_state.saved_topic).replace('{{ESSAY}}', full_essay)
            
            # B∆∞·ªõc n√†y KH√îNG d√πng json_mode=True, ƒë·ªÉ AI t·ª± do vi·∫øt Text ph√¢n t√≠ch tr∆∞·ªõc r·ªìi m·ªõi ƒë·∫øn JSON
            res_grade, _ = generate_content_with_failover(prompt_grade, st.session_state.saved_img, json_mode=False)
            
            status.write("üìù T·ªïng h·ª£p b√°o c√°o...")
            if res_grade:
                # X·ª≠ l√Ω k·∫øt qu·∫£ b·∫±ng h√†m chu·∫©n c·ªßa App ch·∫•m ƒëi·ªÉm
                mk_text, p_data = process_grading_response(res_grade.text)
                st.session_state.grading_result = {
                    "data": p_data, 
                    "markdown": mk_text, # L∆∞u ph·∫ßn text ph√¢n t√≠ch ri√™ng
                    "essay": full_essay, 
                    "topic": st.session_state.saved_topic
                }
                st.session_state.step = 3
                status.update(label="‚úÖ ƒê√£ ch·∫•m xong!", state="complete", expanded=False)
                st.rerun()
            else:
                status.update(label="‚ùå L·ªói k·∫øt n·ªëi AI", state="error")

# ==========================================
# 7. UI: PHASE 3 - GRADING RESULT (EXAMINER UI)
# ==========================================
if st.session_state.step == 3 and st.session_state.grading_result:
    res = st.session_state.grading_result
    g_data = res["data"]
    analysis_text = res["markdown"] # L·∫•y text ph√¢n t√≠ch t·ª´ bi·∫øn ƒë√£ t√°ch
    
    st.markdown("## üõ°Ô∏è K·∫æT QU·∫¢ ƒê√ÅNH GI√Å (EXAMINER REPORT)")
    
    # 1. B·∫£ng ƒëi·ªÉm G·ªëc
    scores = g_data.get("originalScore", {})
    st.markdown("### üìä ƒêi·ªÉm s·ªë hi·ªán t·∫°i")
    cols = st.columns(5)
    cols[0].metric("Task Achievement", scores.get("task_achievement", "-"))
    cols[1].metric("Coherence", scores.get("cohesion_coherence", "-"))
    cols[2].metric("Lexical", scores.get("lexical_resource", "-"))
    cols[3].metric("Grammar", scores.get("grammatical_range", "-"))
    cols[4].metric("OVERALL", scores.get("overall", "-"))
    
    st.markdown("---")

    # 2. Tabs Chi ti·∫øt
    tab_analysis, tab_errors, tab_macro, tab_annotated = st.tabs([
        "üìù Ph√¢n t√≠ch 4 Ti√™u ch√≠", 
        "üî¥ L·ªói Ng·ªØ ph√°p/T·ª´ v·ª±ng", 
        "üîµ L·ªói M·∫°ch l·∫°c/Logic",
        "‚úçÔ∏è B√†i s·ª≠a (Annotated)"
    ])
    
    # TAB 1: HI·ªÇN TH·ªä PH·∫¶N TEXT PH√ÇN T√çCH
    with tab_analysis:
        if analysis_text and len(analysis_text) > 50:
            st.markdown(analysis_text) # Hi·ªÉn th·ªã Markdown chu·∫©n
        else:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ph√¢n t√≠ch chi ti·∫øt.")

    # TAB 2: L·ªñI MICRO (GRAMMAR/VOCAB)
    with tab_errors:
        errors = g_data.get("errors", [])
        micro = [e for e in errors if e.get('category') in ['Grammar', 'Vocabulary', 'Ng·ªØ ph√°p', 'T·ª´ v·ª±ng']]
        if not micro: st.success("Kh√¥ng t√¨m th·∫•y l·ªói ng·ªØ ph√°p ƒë√°ng k·ªÉ.")
        for i, err in enumerate(micro):
            badge = "#DCFCE7" if err.get('category') in ['Grammar','Ng·ªØ ph√°p'] else "#FEF9C3"
            
            # S·ª≠ d·ª•ng HTML th·∫ª div ƒë·ªÉ render card ƒë·∫πp nh∆∞ App Ch·∫•m ƒëi·ªÉm
            st.markdown(f"""
            <div class="error-card">
                <div style="display:flex; justify-content:space-between; margin-bottom:5px;">
                    <span><b>#{i+1} [{err.get('category')}]</b>: {err.get('type')}</span>
                    <span style="background:#eee; padding:2px 8px; border-radius:10px; font-size:0.8em">{err.get('impact_level')}</span>
                </div>
                <div style="background:{badge}; padding:8px; border-radius:5px; margin-bottom:5px;">
                    <s>{err.get('original')}</s> ‚ûî <b>{err.get('correction')}</b>
                </div>
                <small><i>{err.get('explanation')}</i></small>
            </div>
            """, unsafe_allow_html=True)

    # TAB 3: L·ªñI MACRO (COHERENCE)
    with tab_macro:
        macro = [e for e in errors if e.get('category') not in ['Grammar', 'Vocabulary', 'Ng·ªØ ph√°p', 'T·ª´ v·ª±ng']]
        if not macro: st.success("C·∫•u tr√∫c m·∫°ch l·∫°c t·ªët.")
        for err in macro:
            st.markdown(f"""
            <div class="error-card" style="border-left: 5px solid #3B82F6;">
                <b>[{err.get('category')}] {err.get('type')}</b><br>
                V·∫•n ƒë·ªÅ: {err.get('explanation')}<br>
                G·ª£i √Ω: <b>{err.get('correction')}</b>
            </div>
            """, unsafe_allow_html=True)

    # TAB 4: B√ÄI S·ª¨A
    with tab_annotated:
        st.markdown(f'<div class="annotated-text">{g_data.get("annotatedEssay", "")}</div>', unsafe_allow_html=True)

    # 3. Revised Score
    st.markdown("---")
    st.subheader("üìà D·ª± b√°o ƒëi·ªÉm sau khi s·ª≠a l·ªói (Revised Score)")
    rev = g_data.get("revisedScore", {})
    if rev:
        r_cols = st.columns(5)
        r_cols[0].metric("TA (Rev)", rev.get("task_achievement", "-"))
        r_cols[1].metric("CC (Rev)", rev.get("cohesion_coherence", "-"))
        r_cols[2].metric("LR (Rev)", rev.get("lexical_resource", "-"))
        r_cols[3].metric("GRA (Rev)", rev.get("grammatical_range", "-"))
        r_cols[4].metric("OVERALL (Rev)", rev.get("overall", "-"))
        
        if rev.get("logic_re_evaluation"):
            st.info(f"üí° **L∆∞u √Ω c·ªßa Gi√°m kh·∫£o:** {rev.get('logic_re_evaluation')}")

    # 4. Export Buttons
    st.markdown("---")
    d1, d2 = st.columns(2)
    
    docx = create_docx(g_data, res['topic'], res['essay'], analysis_text)
    d1.download_button("üìÑ Download Report (.docx)", docx, "IELTS_Report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
    
    pdf = create_pdf(g_data, res['topic'], res['essay'], analysis_text)
    d2.download_button("üìï Download Report (.pdf)", pdf, "IELTS_Report.pdf", "application/pdf", use_container_width=True)
    
    if st.button("üîÑ L√†m b√†i m·ªõi (Reset)", use_container_width=True):
        st.session_state.step = 1
        st.session_state.guide_data = None
        st.session_state.grading_result = None
        st.session_state.saved_topic = ""
        st.session_state.saved_img = None
        st.rerun()
